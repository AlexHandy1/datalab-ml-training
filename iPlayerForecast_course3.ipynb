{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context\n",
    "\n",
    "## Quick reminder on last course\n",
    "\n",
    "XX\n",
    "\n",
    "## Goal of this course\n",
    "\n",
    "XX\n",
    "\n",
    "\n",
    "# Concepts\n",
    "\n",
    "## Model Selection\n",
    "\n",
    " \n",
    "The first decision you need to make in the model selection process is whether you plan to use a __classifier__ or a __regressor model__. Classifiers make discrete predictions about a datapoint into a finite number of classes while regressors make linear predictions.  \n",
    " \n",
    "Different models work in different ways and are more or less suitable for different problems. Fortunately, however,  understanding these specific differences is not essential to solve your data problems. The python module `scikit learn` contains all of the models that you are likely to need and the format of the data it requires is standardised across models. This makes it very easy to try your data using a myriad of different models and choose the one that performs best on your data.\n",
    " \n",
    "In our current project we use both classifiers and regressors to predict engagement. In the classifier we simply try to predict whether someone has watched any content in the two-week period while in the regressor we attempt to predict the number of minutes watched by the viewer within the two-week period.\n",
    " \n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "To evaluate our models there are various different approaches we can use. As previously mentioned, the final evaluation should ideally be using data that the model has never seen before (the training set). The training set is pushed through the trained model to make predictions and those predictions are compared with the actual targets.\n",
    "\n",
    "For classifiers we can use __the accuracy__ (percentage correct) or __the ROC curve__. When using the accuracy as a model metric it is important to bare in mind what the performance of a completely random model would be. This one depends on the average score. _DETAILS._ Any model you build must be evaluated in terms of improvement over this random model performance. The accuracy is the simplest metric but it gives us little insight into the behaviour of the model. ROC curves (and __the area under the curve__ statistic) give us a greater understanding of the separability of the data (https://en.wikipedia.org/wiki/Receiver_operating_characteristic).\n",
    "\n",
    "For regressors, the evaluation of the model is less straightforward and id usually based upon the average residual between the actual data and the model predictions. __Root mean squared error__ (RMSE) and __mean absolute error__ (MAE) are two commonly used examples of these. Once we have a representation of the error produced by the model we can compare that error with the error of the most simple model of the data (usually the mean). This statistic is known as the coefficient of determination or __R-squared__ and represents the part of variability the model managed to get.\n",
    "\n",
    "We won't tacke both prediction tasks here. This course focused on classification and the next one will focus on regression.\n",
    "\n",
    "# Classification\n",
    "\n",
    "## Random model\n",
    "\n",
    "The first thing to do is to get our data back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We put both training target arrays (regression and classification) in the same txt file\n",
    "# As both target arrays have the same size we just need to split it it two\n",
    "# and get the right part for the prediction task\n",
    "target_training = np.split(np.loadtxt('target_training'), 2)[1].flatten()\n",
    "features_training = pd.read_csv('features_training.csv')\n",
    "\n",
    "# Same for test data\n",
    "target_test = np.split(np.loadtxt('target_test'), 2)[1].flatten()\n",
    "features_test = pd.read_csv('features_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentionned before it is great to have a baseline when talking about model performance. The easiest one when doing with classification task is the random one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
